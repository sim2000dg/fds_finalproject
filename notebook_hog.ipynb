{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.feature import hog\n",
    "import skimage.io as io\n",
    "from skimage.util import view_as_blocks\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, LogisticRegressionCV\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit encoders in order to map string labels to integers\n",
    "# The fact that we are storing the scikit objects makes the encoding reproducible and consistent\n",
    "# We do not need to fit each time, we store the fitted object and use its transform method when needed\n",
    "\n",
    "label_encoder_specific = LabelEncoder().fit(pd.read_csv('dataset_cards/cards.csv')['labels'])  # Specific\n",
    "label_encoder_category = LabelEncoder().fit(pd.read_csv('dataset_cards/cards.csv')['card type'])  # card type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class specifically aimed at digesting and retrieving the images of the cards, together with their\n",
    "    labels, which are also reliably encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str, root_dir: str, transform: str,\n",
    "                 card_category: bool, label_encoder: LabelEncoder,\n",
    "                 subset: str = 'train') -> None:\n",
    "        \"\"\"\n",
    "        Initialization of the CardDataset class\n",
    "        :param csv_path: The path of the csv where to retrieve the necessary information about the images of the cards.\n",
    "        :param root_dir: The root directory for the dataset.\n",
    "        :param transform: Option between Histogram of Gradients ('hog') or Histogram of colors ('rgb_hist').\n",
    "        Pass None in order to avoid transformations (normalization at pixel level is the only operation performed).\n",
    "        :param card_category: Whether the label refers to the card category or to the specific card itself.\n",
    "        :param label_encoder: The scikit-learn LabelEncoder object necessary to map the string labels to integers.\n",
    "        :param subset: Choose between train ('train'), test ('test') and validation ('valid') dataset.\n",
    "        \"\"\"\n",
    "        total_cards = pd.read_csv(csv_path)\n",
    "        try:\n",
    "            self.cards_table = total_cards[total_cards['data set'] == subset]\n",
    "        except KeyError:\n",
    "            raise KeyError('There is no subset in the dataset with the queried label')\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            self.cards_table['labels' if not card_category else 'card type'] = \\\n",
    "                label_encoder.transform(self.cards_table['labels']) if not card_category else \\\n",
    "                label_encoder.transform(self.cards_table['card type'])\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.card_category = card_category\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cards_table)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        card_class = self.cards_table.iat[idx, 2] if not self.card_category else self.cards_table.iat[idx, 3]\n",
    "\n",
    "        if self.transform == 'hog':\n",
    "            representation = np.load(os.path.join(self.root_dir, 'hog',\n",
    "                                                  self.cards_table.iat[idx, 1].split('.')[0] + '.npy'))\n",
    "            representation = np.moveaxis(representation, 2, 0)\n",
    "            \n",
    "        elif self.transform == 'hog_2':\n",
    "            img_path = os.path.join(self.root_dir, self.cards_table.iat[idx, 1])\n",
    "            image = color.rgb2gray(io.imread(img_path))\n",
    "            fd, hog_image = hog(image, orientations=6, pixels_per_cell=(12, 12),\n",
    "                    cells_per_block=(1, 1), block_norm=\"L1\", visualize=True, feature_vector = True)\n",
    "            representation = fd\n",
    "            \n",
    "        elif self.transform is None or self.transform == 'rgb_hist':\n",
    "            img_path = os.path.join(self.root_dir, self.cards_table.iat[idx, 1])\n",
    "            image = io.imread(img_path)\n",
    "            if self.transform == 'rgb_hist':\n",
    "                representation, _ = np.histogramdd((np.reshape(image, (-1, 3))), bins=[np.linspace(0, 256, 6)] * 3)\n",
    "                representation = (representation / representation.sum()).flatten()\n",
    "            else:\n",
    "                representation = np.moveaxis(image/255.0, 2, 0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'There is no transformation function for \\'{self.transform}\\'')\n",
    "\n",
    "        return representation.astype(np.float32), card_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rgb = CardsDataset(csv_path=os.path.join('dataset_cards', 'cards.csv'), root_dir='dataset_cards',\n",
    "                            transform='rgb_hist', card_category=False,\n",
    "                            label_encoder=label_encoder_specific, subset='train')\n",
    "\n",
    "X_rgb = np.array([i[0] for i in training_rgb])\n",
    "y_rgb = np.array([i[1] for i in training_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_rgb = CardsDataset(csv_path=os.path.join('dataset_cards', 'cards.csv'), root_dir='dataset_cards',\n",
    "                            transform='rgb_hist', card_category=False,\n",
    "                            label_encoder=label_encoder_specific, subset='valid')\n",
    "\n",
    "X_t_rgb = np.array([i[0] for i in valid_rgb])\n",
    "y_t_rgb = np.array([i[1] for i in valid_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bins 3D RGB | Train set acc: 0.0699 | Validation set acc: 0.0491\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class=\"multinomial\", n_jobs=os.cpu_count()//2, max_iter = 300, solver=\"sag\", verbose=0).fit(X_rgb, y_rgb)\n",
    "print(f\"11 bins 3D RGB\",\"|\",'Train set acc:', round(clf.score(X_rgb, y_rgb), 4), \"|\",'Validation set acc:',round(clf.score(X_t_rgb, y_t_rgb), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rgb = CardsDataset(csv_path=os.path.join('dataset_cards', 'cards.csv'), root_dir='dataset_cards',\n",
    "                            transform='rgb_hist', card_category=False,\n",
    "                            label_encoder=label_encoder_specific, subset='test')\n",
    "\n",
    "X_t_rgb = np.array([i[0] for i in test_rgb])\n",
    "y_t_rgb = np.array([i[1] for i in test_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bins 3D RGB | Train set acc: 0.0698 | Test set acc: 0.034\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class=\"multinomial\", n_jobs=os.cpu_count()//2, max_iter = 300, solver=\"sag\", verbose=0).fit(X_rgb, y_rgb)\n",
    "print(f\"11 bins 3D RGB\",\"|\",'Train set acc:', round(clf.score(X_rgb, y_rgb), 4), \"|\",'Test set acc:',round(clf.score(X_t_rgb, y_t_rgb), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_hog = CardsDataset(csv_path=os.path.join('dataset_cards', 'cards.csv'), root_dir='dataset_cards',\n",
    "                            transform='hog_2', card_category=False,\n",
    "                            label_encoder=label_encoder_specific, subset='train')\n",
    "\n",
    "X_hog = np.array([i[0] for i in training_hog])\n",
    "y_hog = np.array([i[1] for i in training_hog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hog = np.load('X_hog.npy')\n",
    "y_hog = np.load('y_hog.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7624, 1176)\n",
      "(7624,)\n"
     ]
    }
   ],
   "source": [
    "print(X_hog.shape)\n",
    "print(y_hog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_hog = CardsDataset(csv_path=os.path.join('dataset_cards', 'cards.csv'), root_dir='dataset_cards',\n",
    "                            transform='hog_2', card_category=False,\n",
    "                            label_encoder=label_encoder_specific, subset='valid')\n",
    "\n",
    "X_hog_val = np.array([i[0] for i in validation_hog])\n",
    "y_hog_val = np.array([i[1] for i in validation_hog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 1176)\n",
      "(265,)\n"
     ]
    }
   ],
   "source": [
    "print(X_hog_val.shape)\n",
    "print(y_hog_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hog = CardsDataset(csv_path=os.path.join('dataset_cards', 'cards.csv'), root_dir='dataset_cards',\n",
    "                        transform='hog_2', card_category=False,\n",
    "                        label_encoder=label_encoder_specific, subset='test')\n",
    "    \n",
    "\n",
    "X_t_hog = np.array([i[0] for i in test_hog])\n",
    "y_t_hog = np.array([i[1] for i in test_hog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_hog = np.load('X_hog.npy')\n",
    "y_t_hog = np.load('y_hog.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 1176)\n",
      "(265,)\n"
     ]
    }
   ],
   "source": [
    "print(X_t_hog.shape)\n",
    "print(y_t_hog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning on validation set: model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization parameter C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### C=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1 | Training set acc: 0.8465 | Validation set acc: 0.6868\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(multi_class=\"multinomial\", n_jobs=os.cpu_count()//2, max_iter = 300, solver=\"sag\", verbose=0, C=0.1).fit(X_hog, y_hog)\n",
    "print(f\"C=0.1\",\"|\",'Training set acc:', round(clf.score(X_hog, y_hog), 4), \"|\",'Validation set acc:',round(clf.score(X_hog_val, y_hog_val), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### C=1 (default value), C=10, C=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1 | Training set acc: 0.9963 | Validation set acc: 0.6792\n",
      "C=10 | Training set acc: 0.9999 | Validation set acc: 0.6755\n",
      "C=100 | Training set acc: 0.9999 | Validation set acc: 0.6792\n"
     ]
    }
   ],
   "source": [
    "for c in [1,10,100]:\n",
    "    clf = LogisticRegression(multi_class=\"multinomial\", n_jobs=os.cpu_count()//2, max_iter = 300, solver=\"sag\", verbose=0, C=c).fit(X_hog, y_hog)\n",
    "    print(f\"C={c}\",\"|\",'Training set acc:', round(clf.score(X_hog, y_hog), 4), \"|\",'Validation set acc:',round(clf.score(X_hog_val, y_hog_val), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class=\"multinomial\", n_jobs=os.cpu_count()//2, max_iter = 300, solver=\"sag\", verbose=0, C=0.1).fit(X_hog, y_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.6792\n"
     ]
    }
   ],
   "source": [
    "# RISULTATO MIGLIORE\n",
    "print('Accuracy on test set:', round(clf.score(X_t_hog, y_t_hog), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOC + HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "X_rgb_hog = np.hstack((X_rgb, X_hog))\n",
    "y_rgb_hog = y_hog\n",
    "\n",
    "# test set\n",
    "X_rgb_hog_t = np.hstack((X_t_rgb, X_t_hog))\n",
    "y_rgb_hog_t = y_t_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 139 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iadig\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "clf_rgb_hog = LogisticRegression(multi_class=\"multinomial\", n_jobs=os.cpu_count()//2, solver=\"sag\", verbose=1).fit(X_rgb_hog, y_rgb_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9178\n"
     ]
    }
   ],
   "source": [
    "# training set accuracy\n",
    "print('Accuracy:', round(clf_rgb_hog.score(X_rgb_hog, y_rgb_hog), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6491\n"
     ]
    }
   ],
   "source": [
    "# test set accuracy\n",
    "print('Accuracy:', round(clf_rgb_hog.score(X_rgb_hog_t, y_rgb_hog_t), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try normalizing X_rgb_hog and X_rgb_hog_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_rgb_hog)\n",
    "scaled_X = scaler.transform(X_rgb_hog)\n",
    "scaler.fit(X_rgb_hog_t)\n",
    "scaled_X_t = scaler.transform(X_rgb_hog_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 139 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iadig\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "clf_rgb_hog_scaled = LogisticRegression(multi_class=\"multinomial\", n_jobs=os.cpu_count()//2, solver=\"sag\", verbose=1).fit(scaled_X, y_rgb_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6113\n"
     ]
    }
   ],
   "source": [
    "# training set accuracy\n",
    "print('Accuracy:', round(clf_rgb_hog_scaled.score(scaled_X_t, y_rgb_hog_t), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f722a4e05d3d1c4200d5f08b55ae4a6dfd0e5f63283082903916e7539a9f0ac7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
